{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to try tensorflow, un-comment following two lines\n",
    "# import os\n",
    "# os.environ['KERAS_BACKEND']='tensorflow'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 1, 28, 28)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
    "# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 1,28, 28)/255.\n",
    "X_test = X_test.reshape(-1, 1,28, 28)/255.\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "[[[0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "   0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "   0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "   0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "   0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "   0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "   0.99215686 0.35294118 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.54509804\n",
      "   0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.04313725\n",
      "   0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "   0.09803922 0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "   0.58823529 0.10588235 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "   0.99215686 0.73333333 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.97647059\n",
      "   0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "   0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "   0.98039216 0.71372549 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.09411765 0.44705882\n",
      "   0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "   0.30588235 0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "   0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "   0.52156863 0.04313725 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "   0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.2703 - acc: 0.9264\n",
      "\n",
      "Testing ------------\n",
      "10000/10000 [==============================] - 10s 966us/step\n",
      "\n",
      "test loss:  0.10079015122577548\n",
      "\n",
      "test accuracy:  0.9687\n"
     ]
    }
   ],
   "source": [
    "# Another way to build your CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Conv layer 1 output shape (32, 28, 28)\n",
    "model.add(Convolution2D(\n",
    "    batch_input_shape=(None, 1, 28, 28),\n",
    "    filters=32,\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    padding='same',     # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 1 (max pooling) output shape (32, 14, 14)\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=2,\n",
    "    strides=2,\n",
    "    padding='same',    # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "\n",
    "# Conv layer 2 output shape (64, 14, 14)\n",
    "model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 2 (max pooling) output shape (64, 7, 7)\n",
    "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "\n",
    "# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Fully connected layer 2 to shape (10) for 10 classes\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Another way to define your optimizer\n",
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "# We add metrics to get more results you want to see\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training ------------')\n",
    "# Another way to train the model\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=64,)\n",
    "\n",
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
